# LSTM-CNN-implementation-for-BCI-iv
Analyzing ECoG Signals from Dataset 4 of the BCI Competition
The goal of this project is to analyze these ECoG signals and any patterns within them when recorded by subjects who were asked to flex a certain finger when cued. Understanding how the ECoG signals look like during this specific action-response from the CNS could allow BCIs to process them for use in robotic prosthetics for physically impaired individuals. It may also be used in remotely controlling robotic arms by thought only, allowing for more difficult and dangerous jobs to be risk-free.
	To achieve this, I created a Deep Learning Classification model that took the ECoG signal time-series data as the input and predicted which finger is being flexed in a particular window of time. The dataset used for this project is dataset 4 from the BCI Competition iv. The dataset consists of ECoG signal data measured from 3 epileptic patients. These subjects were fitted with an array of electrodes on the cortex of their brain. Each electrode measured their ECoG signal data and fed it into one channel of information. These patients were made to undergo an experiment, where they were instructed to flex a particular finger whenever the cue for it was displayed in the monitor placed in front of them. Their finger flexions were measured using a data glove. The experiment was conducted for a duration of 10 minutes or 600 seconds. The data was split in the ratio of 2:1 training to test data. This means that 400 seconds of the ECoG signal data and data from the five fingers was set aside as training data and the remaining 200 seconds as test data. The data was measured at a sampling rate of 1000 Hz for the ECoG signal and 25 Hz for the data glove.
